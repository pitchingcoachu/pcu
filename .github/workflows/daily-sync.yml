name: Daily PCU Data Sync and Deploy

on:
  schedule:
    - cron: '0 21 * * *'   # 5:00 PM ET
    - cron: '0 2 * * *'    # 10:00 PM ET
    - cron: '0 12 * * *'   # 8:00 AM ET
  workflow_dispatch:

defaults:
  run:
    shell: bash

jobs:
  sync-and-deploy:
    runs-on: ubuntu-latest
    env:
      R_LIBS_USER: packrat/lib-R
      CSV_CACHE_ROOT: /home/runner/work/pcu/pcu/.cache/csv_sync
      DEPLOY_INSTALL_PACKAGES: "false"
      PITCH_DATA_SYNC_ONLY_CHANGED: "true"
    
    steps:
    - name: Checkout repository
      uses: actions/checkout@v4
      
    - name: Setup R
      uses: r-lib/actions/setup-r@v2
      with:
        r-version: '4.4.0'

    - name: Mark setup-r end
      run: echo "TIMER_MARK setup_r_completed=$(date -u +%Y-%m-%dT%H:%M:%SZ)"
        
    - name: Install system dependencies
      run: |
        step_start=$(date +%s)
        echo "TIMER_START install_system_dependencies=$(date -u +%Y-%m-%dT%H:%M:%SZ)"
        sudo apt-get update
        sudo apt-get install -y \
          libcurl4-openssl-dev \
          libssl-dev \
          libxml2-dev \
          libfontconfig1-dev \
          libharfbuzz-dev \
          libfribidi-dev \
          libfreetype6-dev \
          libpng-dev \
          libjpeg-dev \
          libtiff-dev \
          libfontconfig1 \
          libxcb1 \
          libicu-dev \
          libcairo2-dev \
          libgdal-dev \
          libgeos-dev \
          libproj-dev \
          libudunits2-dev \
          librsvg2-dev
        step_end=$(date +%s)
        echo "TIMER_END install_system_dependencies duration_sec=$((step_end-step_start))"

    - name: Write .Renviron
      run: |
        cat > .Renviron <<'EOF'
        PITCH_MOD_DB_PATH=/home/shiny/pcu_pitch_dashboard/pitch_modifications.db
        PITCH_MOD_EXPORT_PATH=/home/shiny/pcu_pitch_dashboard/pitch_type_modifications.csv
        MYSQL_HOST=${{ secrets.MYSQL_HOST }}
        MYSQL_DB=${{ secrets.MYSQL_DB }}
        MYSQL_USER=${{ secrets.MYSQL_USER }}
        MYSQL_PASSWORD=${{ secrets.MYSQL_PASSWORD }}
        MYSQL_PORT=3306
        MYSQL_SSL_CA=
        # Optional startup-load limits for Neon reads (set via GitHub Secrets)
        PITCH_DATA_MAX_DAYS=${{ secrets.PITCH_DATA_MAX_DAYS }}
        PITCH_DATA_DB_LIMIT=${{ secrets.PITCH_DATA_DB_LIMIT }}
        # Persist shinymanager credentials between deploys
        CREDENTIALS_SQLITE_PATH=/home/shiny/credentials.sqlite
        EOF

    - name: Ensure Packrat library path
      run: mkdir -p packrat/lib-R

    - name: Ensure CSV cache path
      run: mkdir -p .cache/csv_sync

    - name: Cache Packrat library
      uses: actions/cache@v4
      with:
        path: packrat/lib-R
        key: ${{ runner.os }}-r-packrat-${{ hashFiles('packrat/packrat.lock') }}
        restore-keys: |
          ${{ runner.os }}-r-packrat-

    - name: Restore synced CSV cache
      id: csv_cache_restore
      uses: actions/cache/restore@v4
      with:
        path: .cache/csv_sync
        key: ${{ runner.os }}-csv-sync-${{ github.run_id }}
        restore-keys: |
          ${{ runner.os }}-csv-sync-

    - name: Install R packages
      env:
        R_LIBS_USER: packrat/lib-R
      run: |
        step_start=$(date +%s)
        echo "TIMER_START install_r_packages=$(date -u +%Y-%m-%dT%H:%M:%SZ)"
        Rscript install_packages.R
        step_end=$(date +%s)
        echo "TIMER_END install_r_packages duration_sec=$((step_end-step_start))"
          
    - name: Configure rsconnect
      env:
        SHINYAPPS_ACCOUNT: ${{ secrets.SHINYAPPS_ACCOUNT }}
        SHINYAPPS_TOKEN: ${{ secrets.SHINYAPPS_TOKEN }}
        SHINYAPPS_SECRET: ${{ secrets.SHINYAPPS_SECRET }}
        R_LIBS_USER: packrat/lib-R
      run: |
        step_start=$(date +%s)
        echo "TIMER_START configure_rsconnect=$(date -u +%Y-%m-%dT%H:%M:%SZ)"
        Rscript -e "rsconnect::setAccountInfo(name='${{ secrets.SHINYAPPS_ACCOUNT }}', token='${{ secrets.SHINYAPPS_TOKEN }}', secret='${{ secrets.SHINYAPPS_SECRET }}')"
        step_end=$(date +%s)
        echo "TIMER_END configure_rsconnect duration_sec=$((step_end-step_start))"
        
    - name: Sync GCU data
      env:
        R_LIBS_USER: packrat/lib-R
        CSV_CACHE_ROOT: /home/runner/work/pcu/pcu/.cache/csv_sync
        PITCH_DATA_SYNC_ONLY_CHANGED: "true"
      run: |
        step_start=$(date +%s)
        echo "TIMER_START sync_gcu_data=$(date -u +%Y-%m-%dT%H:%M:%SZ)"
        Rscript automated_data_sync.R
        step_end=$(date +%s)
        echo "TIMER_END sync_gcu_data duration_sec=$((step_end-step_start))"
        
    - name: Sync TrackMan media (EdgeR â†’ Cloudinary)
      env:
        R_LIBS_USER: packrat/lib-R
        TM_CLIENT_ID: ${{ secrets.TM_CLIENT_ID }}
        TM_CLIENT_SECRET: ${{ secrets.TM_CLIENT_SECRET }}
        CLOUDINARY_CLOUD_NAME: ${{ secrets.CLOUDINARY_CLOUD_NAME }}
        CLOUDINARY_UPLOAD_PRESET: ${{ secrets.CLOUDINARY_UPLOAD_PRESET }}
        CLOUDINARY_FOLDER: ${{ secrets.CLOUDINARY_FOLDER }}
        TM_LOOKBACK_DAYS: ${{ secrets.TM_LOOKBACK_DAYS }}
        TM_ENV: ${{ secrets.TM_ENV }}
      run: |
        step_start=$(date +%s)
        echo "TIMER_START sync_trackman_media=$(date -u +%Y-%m-%dT%H:%M:%SZ)"
        Rscript trackman_api_sync.R
        step_end=$(date +%s)
        echo "TIMER_END sync_trackman_media duration_sec=$((step_end-step_start))"
        
    - name: Check if data directory exists
      id: check_data
      run: |
        if [ -d "data" ] && [ "$(ls -A data)" ]; then
          echo "data_updated=true" >> $GITHUB_OUTPUT
          echo "Found data files:"
          ls -la data/
        else
          echo "data_updated=false" >> $GITHUB_OUTPUT
          echo "No data directory or no files found"
        fi
        
    - name: Deploy to shinyapps.io
      if: steps.check_data.outputs.data_updated == 'true' || github.event_name == 'workflow_dispatch'
      env:
        R_LIBS_USER: packrat/lib-R
      run: |
        step_start=$(date +%s)
        echo "TIMER_START deploy_shinyapps=$(date -u +%Y-%m-%dT%H:%M:%SZ)"
        Rscript deploy_script.R
        step_end=$(date +%s)
        echo "TIMER_END deploy_shinyapps duration_sec=$((step_end-step_start))"
      
    - name: Commit updated data
      if: steps.check_data.outputs.data_updated == 'true'
      run: |
        step_start=$(date +%s)
        echo "TIMER_START commit_updated_data=$(date -u +%Y-%m-%dT%H:%M:%SZ)"
        git config --local user.email "action@github.com"
        git config --local user.name "GitHub Action"
        git add data/
        if git diff --staged --quiet; then
          echo "No changes to commit"
        else
          git commit -m "Auto-update GCU data $(date)"
          # Rebase safely even with untracked/unstaged files from earlier steps
          git pull --rebase --autostash origin main
          git push
        fi
        step_end=$(date +%s)
        echo "TIMER_END commit_updated_data duration_sec=$((step_end-step_start))"

    - name: Save synced CSV cache
      uses: actions/cache/save@v4
      with:
        path: .cache/csv_sync
        key: ${{ steps.csv_cache_restore.outputs.cache-primary-key }}

    - name: Workflow timing summary
      if: always()
      run: |
        echo "Timing summary is embedded above as TIMER_START/TIMER_END lines per major step."
